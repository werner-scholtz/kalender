name: Performance Profiling Tests

on:
  push:
    branches: [main]
  # TODO: this should not always run for prs.
  pull_request:
    branches: [main]
  # Allow manual trigger
  workflow_dispatch:

jobs:
  performance-profiling:
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'push' || contains(github.event.pull_request.labels.*.name, 'profile')
    runs-on: ubuntu-latest

    env:
      DISPLAY: :99

    steps:
      - uses: actions/checkout@v4
      - uses: subosito/flutter-action@v2
      - name: Install Linux dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl git unzip xz-utils zip libglu1-mesa
          sudo apt-get install -y clang cmake ninja-build pkg-config libgtk-3-dev
          sudo apt-get install -y xvfb
          sudo apt-get install -y libegl1-mesa-dev libgl1-mesa-dev libgles2-mesa-dev
          sudo apt-get install -y mesa-common-dev

      - name: Get Flutter dependencies
        working-directory: ./examples/testing
        run: flutter pub get

      - name: Start virtual display
        run: |
          export DISPLAY=:99
          Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &
          sleep 3

      - name: Run performance profiling tests
        working-directory: ./examples/testing
        env:
          DISPLAY: :99
        run: |
          flutter drive \
            --driver=test_driver/perf_driver.dart \
            --target=integration_test/performance_profiling_test.dart \
            --profile \
            -d linux

      - name: List generated files
        working-directory: ./examples/testing
        run: |
          echo "Generated performance files:"
          find . -name "*.timeline_summary.json" -o -name "*.timeline.json" | head -20

      - name: Upload performance reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-reports-${{ github.run_number }}
          path: |
            examples/testing/build/*.timeline.json
            examples/testing/performance_summary.json
          retention-days: 30

      - name: Commit performance summary to branch
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          # Configure git
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

          # Fetch the performance-results branch
          git fetch origin performance-results:performance-results || echo "Branch doesn't exist yet"

          # Switch to performance-results branch
          git checkout performance-results || git checkout --orphan performance-results

          # Download existing performance summary as baseline (if it exists)
          if git show HEAD:performance_summary.json > baseline_performance.json 2>/dev/null; then
            echo "âœ… Downloaded existing performance summary as baseline"
          else
            echo "â„¹ï¸ No existing performance summary found - this will be the first baseline"
            echo "{}" > baseline_performance.json
          fi

          # Copy the new performance summary
          cp examples/testing/performance_summary.json "performance_summary.json"

          # Run performance comparison if we have a baseline
          if [ -s baseline_performance.json ] && [ "$(cat baseline_performance.json)" != "{}" ]; then
            echo "ðŸ” Running performance comparison..."
            
            # Copy the comparison script from the original branch
            git show ${{ github.sha }}:.github/scripts/compare_performance.py > compare_performance.py
            
            python3 compare_performance.py \
              --current performance_summary.json \
              --baseline baseline_performance.json \
              --output performance_comparison_$(date +%Y%m%d_%H%M%S).md \
              --verbose
            
            # Clean up the temporary script
            rm compare_performance.py
            
            echo "âœ… Performance comparison completed"
          else
            echo "â„¹ï¸ Skipping comparison - no baseline data available"
          fi

          # Add and commit files
          if [ -f "performance_summary.json" ]; then
            git add "performance_summary.json"
            
            # Add comparison report if it exists
            if ls performance_comparison_*.md 1> /dev/null 2>&1; then
              git add performance_comparison_*.md
              echo "ðŸ“Š Added performance comparison report"
            fi
            
            # Create commit with meaningful message
            COMMIT_MSG="Performance data for $(date +%Y-%m-%d) - Commit ${{ github.sha }}"
            if ls performance_comparison_*.md 1> /dev/null 2>&1; then
              COMMIT_MSG="$COMMIT_MSG

          Includes performance comparison report"
            fi
            
            git commit -m "$COMMIT_MSG"
            git push origin performance-results
            
            echo "âœ… Performance summary committed to performance-results branch"
          else
            echo "âŒ No performance summary file found"
          fi

          # Clean up temporary files
          rm -f baseline_performance.json

      - name: Download baseline performance data
        if: github.event_name == 'pull_request'
        run: |
          # Try to download the latest performance summary from main branch
          curl -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
               -H "Accept: application/vnd.github.v3.raw" \
               -o baseline_performance.json \
               "https://api.github.com/repos/${{ github.repository }}/contents/performance_summary.json?ref=performance-results" \
               || echo "No baseline performance data found"

      - name: Compare performance and generate report
        if: github.event_name == 'pull_request'
        run: |
          python3 .github/scripts/compare_performance.py \
            --current examples/testing/performance_summary.json \
            --baseline baseline_performance.json \
            --output performance_report.md \
            --verbose

      - name: Comment PR with performance results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let comment = '## ðŸ“Š Performance Test Results\n\n';

            try {
              if (fs.existsSync('performance_report.md')) {
                const report = fs.readFileSync('performance_report.md', 'utf8');
                comment += report;
              } else {
                comment += 'Performance profiling completed but no comparison data available.\n';
              }
              
              comment += '\n---\n';
              comment += `*Performance test run: ${context.runNumber}*\n`;
              comment += `*Commit: ${context.sha.substring(0, 7)}*`;
              
              // Find existing performance comment and update it, or create new one
              const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
              });
              
              const botComment = comments.find(comment => 
                comment.user.type === 'Bot' && 
                comment.body.includes('ðŸ“Š Performance Test Results')
              );
              
              if (botComment) {
                await github.rest.issues.updateComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  comment_id: botComment.id,
                  body: comment
                });
              } else {
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  body: comment
                });
              }
            } catch (error) {
              console.error('Error posting comment:', error);
              
              // Fallback: post simple comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: 'ðŸ“Š Performance profiling completed. Check the workflow artifacts for detailed results.'
              });
            }
