name: Performance Tests

on:
  push:
    branches: [main]
  # pull_request:
  #   branches: [main]
  schedule:
    - cron: "0 2 * * 1" # Weekly on Mondays

jobs:
  performance-test:
    strategy:
      matrix:
        os: [ubuntu-latest]
        include:
          - os: ubuntu-latest
            platform: linux
            test-device: web-server

    runs-on: ${{ matrix.os }}

    env:
      DISPLAY: :99

    steps:
      - uses: actions/checkout@v4

      - uses: subosito/flutter-action@v2
        with:
          flutter-version: "3.32.0"

      - name: Enable desktop support
        run: |
          flutter config --enable-linux-desktop
          flutter config --enable-macos-desktop  
          flutter config --enable-windows-desktop

      - name: Install Linux dependencies
        if: matrix.os == 'ubuntu-latest'
        run: |
          sudo apt-get update -y
          sudo apt-get install -y curl git unzip xz-utils zip libglu1-mesa
          sudo apt-get install -y clang cmake ninja-build pkg-config libgtk-3-dev
          sudo apt-get install -y xvfb
          sudo apt-get install -y libegl1-mesa-dev libgl1-mesa-dev libgles2-mesa-dev
          sudo apt-get install -y mesa-common-dev

      - name: Install dependencies
        run: |
          cd examples/testing
          flutter pub get

      - name: Start Xvfb
        if: matrix.os == 'ubuntu-latest'
        run: |
          sudo Xvfb $DISPLAY -screen 0 1280x1024x24 > /dev/null 2>&1 &
          echo "Xvfb started on display $DISPLAY"
          sleep 2

      - name: Run performance tests (Linux)
        timeout-minutes: 5
        run: |
          cd examples/testing
          echo "Available devices:"
          flutter devices
          echo "Running performance tests..."
          flutter test integration_test/perf_test.dart --machine --reporter json 2>&1 | tee test_output.log
          # Extract JSON from machine output
          grep -E '^\{.*\}$' test_output.log > test_results.json || echo "{}" > test_results.json
          echo "Test execution completed"

          # Create performance summary with timestamp
          timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          commit_sha="${{ github.sha }}"
          run_number="${{ github.run_number }}"

          cat > performance_summary.json << EOF
          {
            "timestamp": "$timestamp",
            "commit_sha": "$commit_sha",
            "run_number": $run_number,
            "branch": "${{ github.ref_name }}",
            "platform": "${{ matrix.platform }}",
            "test_results": $(cat test_results.json)
          }
          EOF

          echo "Performance summary created:"
          cat performance_summary.json

          # Store results in dashboard data format
          mkdir -p ../../dashboard/data
          cp performance_summary.json "../../dashboard/data/perf_${run_number}_${timestamp}.json"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results-${{ matrix.platform }}-${{ github.run_number }}
          path: |
            examples/testing/test_results.json
            examples/testing/performance_summary.json

      - name: Upload performance JSON (if exists)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-json-${{ matrix.platform }}-${{ github.run_number }}
          path: examples/testing/performance_*.json

      - name: Trigger dashboard build
        if: github.ref == 'refs/heads/main'
        uses: peter-evans/repository-dispatch@v2
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          event-type: build-dashboard

      - name: Trigger dashboard build
        if: github.ref == 'refs/heads/main'
        uses: peter-evans/repository-dispatch@v2
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          event-type: build-dashboard
